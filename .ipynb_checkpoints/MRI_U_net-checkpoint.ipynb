{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea1afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Dec 28 11:22:54 2022\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from typing import Union, Callable, Dict, Tuple\n",
    "import pytorch_lightning as ptl\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0673b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        is_3d: bool = False,\n",
    "        use_normalization: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A recurring structure throughout the UNet architecture.\n",
    "        For clarity's sake, we define it once, and reuse the block.\n",
    "\n",
    "        :param in_features: How many features do we start with?\n",
    "        :param out_features: How many features do we need as output?\n",
    "        :param is_3d: Is this block part of a 3D UNet? If not, will use 2D layers\n",
    "        :param use_normalization: Whether to use a normalization layer between the\n",
    "                                  convolution and ReLU layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if is_3d:\n",
    "            layers = [\n",
    "                nn.Conv3d(in_features, out_features, kernel_size=3, padding=1, bias=False),\n",
    "            ]\n",
    "\n",
    "            if use_normalization:\n",
    "                layers.append(nn.BatchNorm3d(out_features))\n",
    "\n",
    "            layers += [\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv3d(out_features, out_features, kernel_size=3, padding=1, bias=False),\n",
    "            ]\n",
    "\n",
    "            if use_normalization:\n",
    "                layers.append(nn.BatchNorm3d(out_features))\n",
    "\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            \n",
    "        else:\n",
    "            layers = [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, padding=1, bias=False),\n",
    "            ]\n",
    "\n",
    "            if use_normalization:\n",
    "                layers.append(nn.BatchNorm2d(out_features))\n",
    "\n",
    "            layers += [\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_features, out_features, kernel_size=3, padding=1, bias=False),\n",
    "            ]\n",
    "\n",
    "            if use_normalization:\n",
    "                layers.append(nn.BatchNorm2d(out_features))\n",
    "\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through this model\n",
    "\n",
    "        :param x: input data\n",
    "        :return: The processed input data\n",
    "        \"\"\"\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f8c7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(ptl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        is_3d: bool = False,\n",
    "        use_normalization: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Defines an Encoder block for a UNet architecture\n",
    "\n",
    "        :param in_features: How many features do we start with?\n",
    "        :param out_features: How many features do we need as output?\n",
    "        :param is_3d: Is this block part of a 3D UNet? If not, will use 2D layers\n",
    "        :param use_normalization: Whether to use a normalization layer between the\n",
    "                                  convolution and ReLU layers\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if is_3d:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.MaxPool3d(kernel_size=2, stride=2),\n",
    "                DoubleConv(in_features, out_features, is_3d, use_normalization),\n",
    "            )\n",
    "        else:\n",
    "            self.net = nn.Sequential(\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                DoubleConv(in_features, out_features, is_3d, use_normalization),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through this model\n",
    "\n",
    "        :param x: input data\n",
    "        :return: The processed input data\n",
    "        \"\"\"\n",
    "\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5eb7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(ptl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        is_3d: bool = False,\n",
    "        use_transpose: bool = False,\n",
    "        use_normalization: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Defines a Decoder block for a UNet architecture\n",
    "\n",
    "        :param in_features: How many features do we start with?\n",
    "        :param out_features: How many features do we need as output?\n",
    "        :param is_3d: Is this block part of a 3D UNet? If not, will use 2D layers\n",
    "        :param use_transpose: How do we upscale our data?\n",
    "                              If true, will use a transposed convolution\n",
    "                              If False, will use a bi-/triliniar upscale followed\n",
    "                              by a convolution\n",
    "        :param use_normalization: Whether to use a normalization layer between the\n",
    "                                  convolution and ReLU layers\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if use_transpose:\n",
    "            if is_3d:\n",
    "                self.upsample = nn.ConvTranspose3d(\n",
    "                    in_features, in_features // 2, kernel_size=2, stride=2\n",
    "                )\n",
    "            else:\n",
    "                self.upsample = nn.ConvTranspose2d(\n",
    "                    in_features, in_features // 2, kernel_size=2, stride=2\n",
    "                )\n",
    "        else:\n",
    "            if is_3d:\n",
    "                self.upsample = nn.Sequential(\n",
    "                    nn.Upsample(\n",
    "                        scale_factor=2,\n",
    "                        mode=\"trilinear\" if is_3d else \"bilinear\",\n",
    "                        align_corners=True,\n",
    "                    ),\n",
    "                    nn.Conv3d(in_features, in_features // 2, kernel_size=1),\n",
    "                )\n",
    "            else:\n",
    "                self.upsample = nn.Sequential(\n",
    "                    nn.Upsample(\n",
    "                        scale_factor=2,\n",
    "                        mode=\"trilinear\" if is_3d else \"bilinear\",\n",
    "                        align_corners=True,\n",
    "                    ),\n",
    "                    nn.Conv2d(in_features, in_features // 2, kernel_size=1),\n",
    "                )\n",
    "\n",
    "        self.conv = DoubleConv(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "            is_3d=is_3d,\n",
    "            use_normalization=use_normalization,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, skip: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through this model\n",
    "\n",
    "        :param x: Input data\n",
    "        :param skip: The input from the skip connection\n",
    "        :return: The processed input data\n",
    "        \"\"\"\n",
    "        x = self.upsample(x)\n",
    "\n",
    "        # Here is where we would pad if we needed to.\n",
    "\n",
    "        # Concatenate along the channels axis\n",
    "        x = torch.cat([skip, x], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "912aec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(ptl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int,\n",
    "        num_classes: int,\n",
    "        loss_function: Union[nn.Module, Callable, None],\n",
    "        num_layers: int = 5,\n",
    "        input_features: int = 16,\n",
    "        is_3d: bool = False,\n",
    "        use_transpose: bool = True,\n",
    "        use_normalization: bool = True,\n",
    "        lr: float = 1e-3,\n",
    "        final_activation: Union[nn.Module, Callable] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The UNet architecture, as described in the article by Ronneberger et al.\n",
    "        This implementation has been adapted from the PyTorch Lightning Bolts package.\n",
    "\n",
    "        :param input_channels: Number of channels in the input image\n",
    "        :param num_classes: Number of classes in the output\n",
    "        :param num_layers: The depth of the model.\n",
    "        :param loss_function: The loss function to use during training, validation and testing\n",
    "        :param input_features: How many features should the input layer have?\n",
    "        :param is_3d: Do we need to use 3D layers instead of 2D?\n",
    "        :param use_transpose: Whether to use transposed convolutions instead of bi/trilinear\n",
    "                              upsamples in the expanding path\n",
    "         :param use_normalization: Whether to use normalization layers between the convolutions\n",
    "                                  ReLU layers.\n",
    "        :param lr: The learning rate\n",
    "        :param final_activation: What layer should we use as final activation?\n",
    "                                 Not used in forward(), but in the training/validation/testing\n",
    "                                 step functions.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # The following calls are not mandatory for a working LightningModule, but they\n",
    "        # give us some nice-to-haves for our own benefit.\n",
    "\n",
    "        # Saving hyperparameters allows us to track these values in our Tensorboard logger\n",
    "        self.save_hyperparameters(ignore=[\"loss_function\", \"final_activation\"])\n",
    "\n",
    "        # This is used later for our ModelSummary(), giving it an example input so that\n",
    "        # the Callback can run it through the model and keep track of its shape.\n",
    "        self.example_input_array = torch.rand((1, input_channels, 240, 240))\n",
    "\n",
    "        # Back to regular model building!\n",
    "        if num_layers < 1:\n",
    "            raise ValueError(f\"num_layers = {num_layers}, expected: num_layers > 0\")\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.lr = lr\n",
    "        self.final_activation = final_activation\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "        # We start our model architecture with an input DoubleConv\n",
    "        layers = [DoubleConv(input_channels, input_features, is_3d, use_normalization)]\n",
    "\n",
    "        # Down path\n",
    "        feats = input_features\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(DownBlock(feats, feats * 2, is_3d, use_normalization))\n",
    "            feats *= 2\n",
    "\n",
    "        # Up path\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(UpBlock(feats, feats // 2, is_3d, use_transpose, use_normalization))\n",
    "            feats //= 2\n",
    "\n",
    "        # Our final convolution\n",
    "        if is_3d:\n",
    "            layers.append(nn.Conv3d(feats, num_classes, kernel_size=1))\n",
    "        else:\n",
    "            layers.append(nn.Conv2d(feats, num_classes, kernel_size=1))\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through this model\n",
    "\n",
    "        :param x: Input data\n",
    "        :return: The processed input data\n",
    "        \"\"\"\n",
    "        xi = [self.layers[0](x)]\n",
    "        # Down path\n",
    "        for layer in self.layers[1: self.num_layers]:\n",
    "            xi.append(layer(xi[-1]))\n",
    "        # Up path\n",
    "        for i, layer in enumerate(self.layers[self.num_layers: -1]):\n",
    "            xi[-1] = layer(xi[-1], xi[-2 - i])\n",
    "        return self.layers[-1](xi[-1])\n",
    "\n",
    "    def configure_optimizers(self) -> Dict[str, torch.optim.Optimizer]:\n",
    "        # Here we define our optimizer, and any learning rate scheduling\n",
    "        # Adam usually works well, so we just use that\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                # As for the scheduler, we reduce our learning rate whenever our validation\n",
    "                # loss doesn't decrease for 5 epochs in a row.\n",
    "                # Other schedulers exist, but using one is not mandatory, you'll just have a\n",
    "                # fixed learning rate during the course of training.\n",
    "                \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                    optimizer=optimizer,\n",
    "                    mode=\"min\",\n",
    "                    factor=0.1,\n",
    "                    patience=5,\n",
    "                    verbose=True,\n",
    "                ),\n",
    "                \"monitor\": \"val_loss\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def training_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        # This is the same type of code that you'd usually find in your\n",
    "        # original PyTorch training for loop.\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        if self.final_activation is not None:\n",
    "            y_hat = self.final_activation(y_hat)\n",
    "\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        output = {\"loss\": loss}\n",
    "\n",
    "        # self.log() and self.log_dict() are more used for making sure\n",
    "        # that the current progress is displayed properly, and written\n",
    "        # by the TensorboardLogger. the use of either is not mandatory\n",
    "        self.log_dict(output, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        # training_step() has to return either:\n",
    "        #   - A scalar of the loss\n",
    "        #   - A dictionary, with the key \"loss\" present\n",
    "        # this return is used by Lightning internally\n",
    "        return output\n",
    "\n",
    "    def validation_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> None:\n",
    "        # This is also where we could log images to Tensorboard\n",
    "        # to visually track our progress.\n",
    "\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        if self.final_activation is not None:\n",
    "            y_hat = self.final_activation(y_hat)\n",
    "\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        output = {\"val_loss\": loss}\n",
    "        self.log_dict(output, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        # validation_step() does _not_ require a return,\n",
    "        # in fact, you don't even need to use the same\n",
    "        # loss function as you do in training_step().\n",
    "\n",
    "    def test_step(\n",
    "        self, batch: Tuple[torch.Tensor, torch.Tensor], batch_idx: int\n",
    "    ) -> None:\n",
    "        # Quite similar to, if not the same as, the validation_step()\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        if self.final_activation is not None:\n",
    "            y_hat = self.final_activation(y_hat)\n",
    "\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        output = {\"test_loss\": loss}\n",
    "        self.log_dict(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80d429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
